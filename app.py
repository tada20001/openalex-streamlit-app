# app.py
import streamlit as st
import datetime
import os
import pandas as pd
import io
from modules import url_builder
from modules import data_fetcher
from modules import data_processor

# ==============================================================================
# 1. UI (í™”ë©´ êµ¬ì„±)
# ==============================================================================

# ê¸°ë³¸ ê²€ìƒ‰ì–´ ì„¤ì •
DEFAULT_OR_KEYWORDS = (
    "MRAM, PRAM, RRAM, FeRAM, OxRAM, CBRAM, "
    "\"Resistive Random-Access Memory\", \"Magnetoresistive Random-Access Memory\", "
    "\"Ferroelectric Random-Access Memory\", \"non-volatile memory\", \"nonvolatile memory\", "
    "\"emerging memory\", \"next-generation memory\", \"storage class memory\", "
    "\"novel memory\", \"advanced memory\", memristor, memristive"
)

st.set_page_config(layout="wide")
st.title(" OpenAlex ë…¼ë¬¸ ë°ì´í„° ìˆ˜ì§‘")

# ì‘ì—… ë‹¨ê³„ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'step' not in st.session_state:
    st.session_state.step = "start"

# --- ì…ë ¥ ì„¹ì…˜: ì‘ì—… ì™„ë£Œ(done) ë˜ëŠ” ì‹œì‘ ì „(start) ìƒíƒœì¼ ë•Œë§Œ í‘œì‹œ ---
if st.session_state.step in ["start", "done"]:
    with st.container(border=True):
        st.header("1. ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •")
        col1, col2 = st.columns(2)

        with col1:
            or_keywords_input = st.text_area("OR í‚¤ì›Œë“œ (í•˜ë‚˜ë¼ë„ í¬í•¨)", value=DEFAULT_OR_KEYWORDS, height=250)
        with col2:
            and_keywords_input = st.text_area("AND í‚¤ì›Œë“œ (ëª¨ë‘ í¬í•¨)", "neuromorphic", height=100)

             # --- 2. ê²€ìƒ‰ ê¸°ê°„ ì„¤ì • (ìŠ¬ë¼ì´ë” ë°©ì‹) ---
            st.markdown("---") # êµ¬ë¶„ì„  ì¶”ê°€
            st.subheader("2. ê²€ìƒ‰ ê¸°ê°„")
            current_year = datetime.datetime.now().year

            # st.sliderë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ë„ ë²”ìœ„ ì„ íƒ
            selected_years = st.slider(
                "ê²€ìƒ‰í•  ì—°ë„ ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
                min_value=1980,
                max_value=current_year + 1,
                value=(2015, current_year) # ê¸°ë³¸ê°’
            )

            # ìŠ¬ë¼ì´ë” ê²°ê³¼ì—ì„œ ì‹œì‘/ì¢…ë£Œ ì—°ë„ ì¶”ì¶œ
            start_year, end_year = selected_years

        with st.expander("ìƒì„¸ ê²€ìƒ‰ ì¡°ê±´ í¼ì¹˜ê¸°"):
            type_options = {
                'í•™ìˆ  ë…¼ë¬¸ (Article)': 'article', 'í•™íšŒ ë°œí‘œ ìë£Œ (Conference Paper)': 'conference',
                'ë„ì„œ ì±•í„° (Book Chapter)': 'book-chapter', 'ë¦¬ë·° (Review)': 'review', 'í•™ìœ„ ë…¼ë¬¸ (Dissertation)': 'dissertation'
            }
            selected_includes = st.multiselect("í¬í•¨í•  ë¬¸ì„œ ìœ í˜•", options=list(type_options.keys()), default=['í•™ìˆ  ë…¼ë¬¸ (Article)', 'í•™íšŒ ë°œí‘œ ìë£Œ (Conference Paper)'])
            include_types_values = [type_options[key] for key in selected_includes]

            search_mode_option = st.radio("ê²€ìƒ‰ ë²”ìœ„", ('ë„“ê²Œ ê²€ìƒ‰ (í¬ê´„ì )', 'ì •í™•í•˜ê²Œ ê²€ìƒ‰ (í•µì‹¬ì )'), horizontal=True,
                help="- ë„“ê²Œ ê²€ìƒ‰: ì œëª©, ì´ˆë¡, í‚¤ì›Œë“œ, ì£¼ì œ ë“±ì—ì„œ ê²€ìƒ‰\n- ì •í™•í•˜ê²Œ ê²€ìƒ‰: ì œëª©ê³¼ ì´ˆë¡ì—ì„œë§Œ ê²€ìƒ‰")

            email = st.text_input("API ì‚¬ìš© ì´ë©”ì¼ ì£¼ì†Œ", "test@example.com", help="ë°˜ë“œì‹œ ë³¸ì¸ì˜ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì•¼ ê²€ìƒ‰ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # --- ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ë²„íŠ¼ ---
    if st.button("1. ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘", type="primary", use_container_width=True):
        st.session_state.step = "collecting"
        # UI ì…ë ¥ ê°’ë“¤ì„ ì„¸ì…˜ì— ì €ì¥
        st.session_state.ui_inputs = {
        "email": email,
        "or_keywords_input": or_keywords_input,
        "and_keywords_input": and_keywords_input,
        "start_year": start_year,
        "end_year": end_year,
        "include_types_values": include_types_values,
        "search_mode": 'broad' if 'ë„“ê²Œ' in search_mode_option else 'precise'
    }
        st.rerun()

# ==============================================================================
# 2. ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„
# ==============================================================================
if st.session_state.step == "collecting":
    with st.spinner("URL ìƒì„± ë° ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
        # ì €ì¥ëœ ì…ë ¥ ê°’ìœ¼ë¡œ URL ìƒì„±
        inputs = st.session_state.ui_inputs.copy()
        search_mode = inputs.pop('search_mode')

        params = url_builder.prepare_params(**inputs)
        if search_mode == 'broad':
            api_url = url_builder.create_broad_query(**params)
        else:
            api_url = url_builder.create_precise_query(**params)

        st.subheader("ğŸ“ˆ ë°ì´í„° ìˆ˜ì§‘ í˜„í™©")
        DATA_DIR = "data"
        if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)
        output_filepath = os.path.join(DATA_DIR, "collected_data.jsonl")

        data_fetcher.fetch_and_save_incrementally(api_url, output_filepath)

        st.session_state['data_filepath'] = output_filepath
        st.session_state.step = "processing" # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „í™˜
        st.rerun()

# ==============================================================================
# 3. ë°ì´í„° ì •ì œ ë‹¨ê³„
# ==============================================================================
if st.session_state.step == "processing":
    filepath = st.session_state['data_filepath']
    with st.spinner(f"'{filepath}' íŒŒì¼ì„ ì •ì œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        # data_processorì˜ ë§ˆìŠ¤í„° í•¨ìˆ˜ í˜¸ì¶œ
        final_df = data_processor.process_and_refine_data(filepath)
        st.session_state['final_df'] = final_df
        st.session_state.step = "done"
    st.rerun()

# ==============================================================================
# 4. ìµœì¢… ê²°ê³¼ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ/ì´ˆê¸°í™”
# ==============================================================================
if st.session_state.step == "done":
    st.subheader("ğŸ“Š ìµœì¢… ì •ì œ ë°ì´í„°")
    st.dataframe(st.session_state['final_df'])
    st.info(f"ì´ {len(st.session_state['final_df'])}ê°œì˜ ë…¼ë¬¸ ë°ì´í„°ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

    col1_dl, col2_reset = st.columns(2)
    with col1_dl:
        @st.cache_data
        def convert_df_to_excel(df):
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='Sheet1')
            processed_data = output.getvalue()
            return processed_data

        excel_data = convert_df_to_excel(st.session_state['final_df'])
        st.download_button(
            label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=excel_data, file_name="ìµœì¢…_ë³´ê³ ì„œ_OpenAlex.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)

    with col2_reset:
        if st.button("ìƒˆ ê²€ìƒ‰ ì‹œì‘", type="secondary", use_container_width=True):
            if 'data_filepath' in st.session_state:
                filepath = st.session_state['data_filepath']
                if os.path.exists(filepath):
                    os.remove(filepath)
                    st.toast(f"'{filepath}' ë°ì´í„° íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

            for key in list(st.session_state.keys()):
                del st.session_state[key]

            st.rerun()